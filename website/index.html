<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
    <!-- Replace the content tag with appropriate information -->
    <meta name="description" content="DESCRIPTION META TAG" />
    <meta property="og:title" content="SOCIAL MEDIA TITLE TAG" />
    <meta
      property="og:description"
      content="SOCIAL MEDIA DESCRIPTION TAG TAG"
    />
    <meta property="og:url" content="URL OF THE WEBSITE" />
    <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
    <meta property="og:image" content="static/image/your_banner_image.png" />
    <meta property="og:image:width" content="1200" />
    <meta property="og:image:height" content="630" />

    <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG" />
    <meta
      name="twitter:description"
      content="TWITTER BANNER DESCRIPTION META TAG"
    />
    <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
    <meta
      name="twitter:image"
      content="static/images/your_twitter_banner_image.png"
    />
    <meta name="twitter:card" content="summary_large_image" />
    <!-- Keywords for your paper to be indexed by-->
    <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Under the Surface: Tracking the Artifactuality of LLM-Generated Data</title>
    <link rel="icon" type="image/x-icon" href="static/images/favicon.ico" />
    <link
      href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
      rel="stylesheet"
    />

    <link rel="stylesheet" href="static/css/bulma.min.css" />
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css" />
    <link rel="stylesheet" href="static/css/bulma-slider.min.css" />
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css" />
    <link
      rel="stylesheet"
      href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css"
    />
    <link rel="stylesheet" href="static/css/index.css" />

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
    <script defer src="static/js/fontawesome.all.min.js"></script>
    <script src="static/js/bulma-carousel.min.js"></script>
    <script src="static/js/bulma-slider.min.js"></script>
    <script src="static/js/index.js"></script>
  </head>
  <body>
    <section class="hero is-warning">
        <div class="hero-body">
          <p class="title">
            Under Construction
          </p>
          <p class="subtitle">
            Internal preview only
          </p>
        </div>
      </section>
    <section class="hero">
      <div class="hero-body">
        <div class="container is-max-desktop">
          <div class="columns is-centered">
            <div class="column has-text-centered">
              <h1 class="title is-1 publication-title">
                Under the Surface: Tracking the Artifactuality of LLM-Generated Data
              </h1>
              <div class="is-size-5 publication-authors">
                <!-- Paper authors -->
                <span class="author-block">
                  <a href="https://debaratidas94.github.io/" target="_blank"
                    >Debarati Das</a
                  ><sup>*</sup>,</span
                >
                <span class="author-block">
                  <a href="https://karinjd.github.io/" target="_blank"
                    >Karin de Langis</a
                  ><sup>*</sup>,</span
                >
                <span class="author-block">
                  <a href="https://anmartin94.github.io/" target="_blank"
                    >Anna Martin-Boyle</a
                  ><sup>*</sup>,
                </span>
                <span class="author-block">
                  <a href="https://sites.google.com/view/jaehyungkim" target="_blank"
                    >Jaehyung Kim</a
                  ><sup>*</sup>,
                </span>
                <span class="author-block">
                  <a href="https://mimn97.github.io/" target="_blank"
                    >Minhwa Lee</a
                  ><sup>*</sup>,
                </span>
                <span class="author-block">
                  <a href="https://zaemyung.github.io/" target="_blank"
                    >Zae Myung Kim</a
                  ><sup>*</sup>,
                </span>
                <span class="author-block">
                  <a href="https://www.shirley.id/" target="_blank"
                    >Shirley Anugrah Hayati</a
                  >,
                </span>
                <span class="author-block">
                  <a target="_blank"
                    >Risako Owan</a
                  >,
                </span>
                <span class="author-block">
                  <a href="https://bin-hu.com/" target="_blank"
                    >Bin Hu</a
                  >,
                </span>
                <span class="author-block">
                  <a target="_blank"
                    >Ritik Sachin Parkar</a
                  >,
                </span>
                <span class="author-block">
                  <a href="https://kooryan.netlify.app/" target="_blank"
                    >Ryan Koo</a
                  >,
                </span>
                <span class="author-block">
                  <a target="_blank"
                    >Jong Inn Park</a
                  >,
                </span>
                <span class="author-block">
                  <a target="_blank"
                    >Aahan Tyagi</a
                  >,
                </span>
                <span class="author-block">
                  <a target="_blank"
                    >Libby Ferland</a
                  >,
                </span>
                <span class="author-block">
                  <a target="_blank"
                    >Sanjali Roy</a
                  >,
                </span>
                <span class="author-block">
                  <a target="_blank"
                    >Vincent Liu</a
                  >,
                </span>
                <span class="author-block">
                  <a href="https://dykang.github.io/" target="_blank"
                    >Dongyeop Kang</a
                  >
                </span>
              </div>

              <div class="is-size-5 publication-authors">
                <span class="author-block">Minnesota NLP Group, University of Minnesota</apsn>
                <span class="eql-cntrb"
                  ><small
                    ><br /><sup>*</sup>Indicates Equal Contribution</small
                  ></span
                >
              </div>

              <div class="notification is-warning is-light left">
                <button class="delete"></button>
                <b>Comment:</b> Everyone please check the link you'd like to add on your name. - Bin
            </div>

              <div class="column has-text-centered">
                <div class="publication-links">
                  <!-- Arxiv PDF link -->
                  <span class="link-block">
                    <a
                      href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf"
                      target="_blank"
                      class="external-link button is-normal is-rounded is-dark is-static"
                    >
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Paper</span>
                    </a>
                  </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a
                      href="https://github.com/YOUR REPO HERE"
                      target="_blank"
                      class="external-link button is-normal is-rounded is-dark is-static"
                    >
                      <span class="icon">
                        <i class="fab fa-github"></i>
                      </span>
                      <span>Code</span>
                    </a>
                  </span>

                  <!-- ArXiv abstract Link -->
                  <span class="link-block">
                    <a
                      href="https://arxiv.org/abs/<ARXIV PAPER ID>"
                      target="_blank"
                      class="external-link button is-normal is-rounded is-dark is-static"
                    >
                      <span class="icon">
                        <i class="ai ai-arxiv"></i>
                      </span>
                      <span>arXiv</span>
                    </a>
                  </span>

                  <!-- Huggingface daya Link -->
                  <span class="link-block">
                    <a
                      href="https://"
                      target="_blank"
                      class="external-link button is-normal is-rounded is-dark is-static"
                    >
                      <span class="icon">
                        <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard-data" viewBox="0 0 16 16">
                          <path d="M4 11a1 1 0 1 1 2 0v1a1 1 0 1 1-2 0zm6-4a1 1 0 1 1 2 0v5a1 1 0 1 1-2 0zM7 9a1 1 0 0 1 2 0v3a1 1 0 1 1-2 0z"/>
                          <path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1h1a1 1 0 0 1 1 1V14a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V3.5a1 1 0 0 1 1-1h1z"/>
                          <path d="M9.5 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5zm-3-1A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0z"/>
                        </svg>
                      </span>
                      <span>Data (on Huggingface)</span>
                    </a>
                  </span>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>

    <section class="section hero">
      <div class="columns is-centered has-text-centered">
        <div class="column is-5 is-offset-1">
          <div class="container is-max-desktop">
            <div class="columns is-centered">
              <div class="column is-four-fifths">
                  <img
                    src="static/images/iceberg_modified.jpg"
                    class="center-image"
                  />
                </div>
              </div>
            </div>
          </div>
        <!-- Paper abstract -->
        <div class="column is-5">
          <div class="container is-max-desktop">
            <div class="columns has-text-centered">
              <div class="column is-four-fifths">
                <h2 class="title">Abstract</h2>
                <div class="content has-text-justified">
                  <p>
                    This work delves into the expanding role of large language models (LLMs) in generating artificial data, traditionally the domain of human expertise. It critically examines the quality and implications of LLM-generated artificial data, comparing it with human data across various benchmarks. Despite its capability to match human performance, the paper reveals significant hidden disparities, especially in complex tasks where LLMs often miss the nuanced understanding intrinsic to human-generated content. This study conducts comprehensive stress tests on diverse LLM-generated data, proposes novel evaluation methods, and emphasizes the need for ethical practices in data creation and use. It highlights the LLMs' shortcomings in replicating human traits and behaviors, underscoring the importance of addressing biases and limitations in LLM-generated content for future research and development.
                  </p>
                </div>
              </div>
            </div>
          </div>
        </div>
        <!-- End paper abstract -->
        </div>
      </div>
    </section>
    
    
    <section class="section hero is-small is-light">
      <div class="container is-max-desktop">
        <div class="notification is-warning is-light">
            <button class="delete"></button>
            <b>Comment:</b> Should we delete this section? - Bin
        </div>
        <div class="columns is-centered">
          <div class="column">
            <div class="content">
              <h2 class="title is-3">Research Questions</h2>
              <div class="level-set has-text-justified">
                <p><b>RQ1</b> What is the nature of SOTA artificial data? How does it compare to human data, and what artifacts does it contain?</p>
                <p><b>RQ2</b> Does training on artificial data compromise performance outcomes compared to similar human-generated data?</p>
                <p><b>RQ3</b> How specific are the artifacts of artificial data to certain types of data produced by large language models (LLMs), and how much do they apply to all types of data generated by LLMs?</p>
              </div>
            </div>
          </div>
          
          <div class="column">
            <div class="content">
              <h2 class="title is-3">Takeaways</h2>
              <div class="level-set has-text-justified">
                <ul>
                  <li>LLMs struggle to respond effectively when faced with unknown or unfamiliar situations.</li>
                  <li>LLMs demonstrate a subpar understanding of complex human opinions and interactions.</li>
                  <li>LLMs are deficient in accurately mirroring human behavior for particular tasks</li>
                  <li>Models trained on LLM data containing the above issues have degraded performance.</li>
                </ul>
              </div>
              <!-- <img src="static\images\order_effect.jpg" alt="Testing methods" class="center-image"/> -->
            </div>
          </div>
        </div>
      </div>
    </section>

    <section class="section hero is-small">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column is-full">
            <div class="content">
              <h2 class="title is-3">Types of Artificial Data</h2>
              <img src="static\images\type_data.jpg" alt="type_data.jpg" class="center-image"/>
              <div class="level-set has-text-justified">
                <p>
                  <ul>
                    <li><b>Free-Form Text</b> written by an LLM, often used to compensate for data scarcity issues and used for pretraining and/or finetuning.</li>
                    <li><b>Task Labels</b> for classification tasks over textual input, bypassing the need for human annotators.</li>
                    <li><b>Instruction prompts</b> written by LLMs for instruction fine-tuning, eliminating the need for humans to write comprehensive sets of diverse instructions.</li>
                    <li><b>Preference</b> specifically evaluating which text is better, is useful for human alignment tasks such as training reward models used in RLHF.</li>
                    <li><b>Simulation</b> where two large language model (LLM) agents converse, has potential for enhancing model performance and simulating intricate social interactions, according to initial studies.</li>
                  </ul>
                </p>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>


    <section class="section hero is-small is-light">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column is-full">
            <div class="content">
              <h2 class="title is-3">Main Contributions</h2>
              <div class="level-set has-text-justified">
              <ul>
                <li>We <b>aggregate and conduct comprehensive stress tests</b> on various data generated by LLMs, offering a thorough evaluation of the quality, consistency, and reliability of LLM outputs across diverse models and scenarios, thereby providing a groundbreaking insight into their strengths and weaknesses for future research and development.</li>
                <li>We propose novel <b>alternative methods for assessing LLM-generated data</b>, emphasizing nuanced, context-sensitive approaches that go beyond traditional metrics to more effectively create realistic, human-aligned content.</li>
                <li>Our research <b>emphasizes the critical need for responsible and ethical practices in creating and using LLM-generated data</b>, advocating for collaborative efforts among stakeholders to address biases, increase diversity, and deepen the understanding of complex human opinions in LLM outputs, thereby ensuring their development benefits society ethically and sustainably.</li>
                </ul>
              </div>
            </div>
          </div>

    </section>

    <section class="section hero is-small">
        <div class="container is-max-desktop">
            <div class="content">
                <h2 class="title is-3">Main Findings</h2>
                <div class="notification is-danger is-light">
                    <button class="delete"></button>
                    <b>TO DO</b>
                    <p>Current plots are just place holder.</p>
                </div>
                <ul>
                    <li>LLMs tend to fall short in complex tasks, often <b>missing the subtleties and nuanced understanding</b> found in human-generated data, particularly in areas like minority perspectives and complex preferences. </li>
                            <div class="hero-body">
                                <div class="container">
                                    <div id="results-carousel" class="carousel results-carousel">
                                        <div class="item">
                                            <p class="subtitle has-text-centered"><b>Free Text</b> - section 5.2</p>
                                            <img src="static/images/attributef1scatter.JPG" alt="MY ALT TEXT" style="max-height: 500px">
                                            <p class="subtitle is-6 has-text-centered">
                                                Scatterplot comparing (a) the label-level F1 differences in performance for models trained on human-text vs machine-text, and (b) selected mean label-level attribute difference. For these attributes---neutral emotion, sadness, metaphor, and joy---we find <i>a correlation between how much training on only machine text decreases the F1 score on the test set</i>, and how much the high-level attributes such as <i>sadness</i> differ among the machine and human texts.
                                            </p>
                                        </div>
                            
                                        <div class="item">
                                            <p class="subtitle has-text-centered"><b>Task Labels</b> - section 6.2</p>
                                            <img src="static/images/sorted-inter_alpha0.8_whole_1e-05-before-after.JPG" alt="MY ALT TEXT" style="max-height: 500px">
                                            <p class="subtitle is-6 has-text-centered">
                                                The label distribution graph for the Sentiment and SChem Dataset, before and after fine-tuning a RoBERTa classifier, indicates that <i>pre-existing biases in label distribution</i>---such as imbalances in the original dataset (1st order)---<i>tend to become more pronounced after the fine-tuning process (2nd order).</i>
                                            </p>
                                        </div>
                                    </div>
                                </div>
                            </div>
                    <li>LLM-generated texts frequently <b>lack human traits</b> such as humor and sarcasm and <b>do not mirror the structural complexities and styles</b> typical in human writing and conversations, especially in problem-solving scenarios.</li>
                    <div class="hero-body">
                        <div class="container">
                            <div id="results-carousel" class="carousel results-carousel">
                                <div class="item">
                                    <p class="subtitle has-text-centered"><b>Free Text</b> - section 5.2</p>
                                    <img src="static/images/attributef1scatter.JPG" alt="MY ALT TEXT" style="max-height: 500px">
                                    <p class="subtitle is-6 has-text-centered">
                                        Scatterplot comparing (a) the label-level F1 differences in performance for models trained on human-text vs machine-text, and (b) selected mean label-level attribute difference. For these attributes---neutral emotion, sadness, metaphor, and joy---we find <i>a correlation between how much training on only machine text decreases the F1 score on the test set</i>, and how much the high-level attributes such as <i>sadness</i> differ among the machine and human texts.
                                    </p>
                                </div>
                    
                                <div class="item">
                                    <p class="subtitle has-text-centered"><b>Task Labels</b> - section 6.2</p>
                                    <img src="static/images/sorted-inter_alpha0.8_whole_1e-05-before-after.JPG" alt="MY ALT TEXT" style="max-height: 500px">
                                    <p class="subtitle is-6 has-text-centered">
                                        The label distribution graph for the Sentiment and SChem Dataset, before and after fine-tuning a RoBERTa classifier, indicates that <i>pre-existing biases in label distribution</i>---such as imbalances in the original dataset (1st order)---<i>tend to become more pronounced after the fine-tuning process (2nd order).</i>
                                    </p>
                                </div>
                            </div>
                        </div>
                    </div>
                    <li>These shortcomings become evident as LLMs struggle in <b>unfamiliar situations</b>, generating <b>incorrect outputs</b>, <b>exhibiting biases</b>, and failing to accurately replicate human behavior, leading to <b>decreased performance in models trained on such LLM-generated data</b>.</li>
                    <div class="hero-body">
                        <div class="container">
                            <div id="results-carousel" class="carousel results-carousel">
                                <div class="item">
                                    <p class="subtitle has-text-centered"><b>Free Text</b> - section 5.2</p>
                                    <img src="static/images/attributef1scatter.JPG" alt="MY ALT TEXT" style="max-height: 500px">
                                    <p class="subtitle is-6 has-text-centered">
                                        Scatterplot comparing (a) the label-level F1 differences in performance for models trained on human-text vs machine-text, and (b) selected mean label-level attribute difference. For these attributes---neutral emotion, sadness, metaphor, and joy---we find <i>a correlation between how much training on only machine text decreases the F1 score on the test set</i>, and how much the high-level attributes such as <i>sadness</i> differ among the machine and human texts.
                                    </p>
                                </div>
                    
                                <div class="item">
                                    <p class="subtitle has-text-centered"><b>Task Labels</b> - section 6.2</p>
                                    <img src="static/images/sorted-inter_alpha0.8_whole_1e-05-before-after.JPG" alt="MY ALT TEXT" style="max-height: 500px">
                                    <p class="subtitle is-6 has-text-centered">
                                        The label distribution graph for the Sentiment and SChem Dataset, before and after fine-tuning a RoBERTa classifier, indicates that <i>pre-existing biases in label distribution</i>---such as imbalances in the original dataset (1st order)---<i>tend to become more pronounced after the fine-tuning process (2nd order).</i>
                                    </p>
                                </div>
                            </div>
                        </div>
                    </div>
                </ul>
            </div>
        </div>
    </section>


    <section class="section hero is-small is-light">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="content">
                    <h2 class="title is-3">Qualitative Analysis</h2>
                </div>
                <div class="notification is-danger is-light">
                    <button class="delete"></button>
                    <b>TO DO</b>
                </div>
            </div>
        </div>
    </section>

    <!--BibTex citation -->
    <section class="section" id="BibTeX">
      <div class="container is-max-desktop content">
        <h2 class="title">BibTeX</h2>
        <pre><code>BibTex Code Here</code></pre>
      </div>
    </section>
    <!--End BibTex citation -->

    <footer class="footer">
      <div class="container">
        <div class="columns is-centered">
          <div class="column is-8">
            <div class="content">
              <p>
                This page was built using the
                <a
                  href="https://github.com/eliahuhorwitz/Academic-project-page-template"
                  target="_blank"
                  >Academic Project Page Template</a
                >
                which was adopted from the <a
                  href="https://nerfies.github.io"
                  target="_blank"
                  >Nerfies</a
                > project page.
              </p>
            </div>
          </div>
        </div>
      </div>
    </footer>

    <!-- Statcounter tracking code -->

    <!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->
  </body>
</html>
