{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b180c618",
   "metadata": {},
   "source": [
    "- All codes are written by Jaehyung Kim (jaehyungkim@kaist.ac.kr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "990c406f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import json\n",
    "import copy\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fb37baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta, datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbe29d5",
   "metadata": {},
   "source": [
    "# Dataset Load \n",
    "- From https://github.com/MikeWangWZHL/Solo-Performance-Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "356c4527",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = './datasets/logic_grid_puzzle_200.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fc9ba37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['idx', 'inputs', 'targets', 'multiple_choice_targets', 'multiple_choice_scores'])\n",
      "idx\n",
      "0\n",
      "inputs\n",
      "Q: There are 4 houses in a row, numbered 1 on the left to 4 on the right. There is one person living in each house. The people in these houses have different characteristics:\n",
      " - Each person has different flowers in their foyer: one has a carnations arrangement, one has a bouquet of daffodils, one has a vase of tulips, and one has a bouquet of lilies\n",
      " - Each person plays a different musical instrument: one is a guitarist, one is a pianist, one is a percussionist, and one is a flutist\n",
      "\n",
      "Clue(s):\n",
      "1. The flutist lives in the second house.\n",
      "2. The person who has a vase of tulips lives directly left of the guitarist.\n",
      "3. The person who has a bouquet of lilies lives directly left of the person who has a carnations arrangement.\n",
      "4. There is one house between where the flutist lives and where the pianist lives.\n",
      "\n",
      "What is the number of the house where the person who has a vase of tulips lives?\n",
      "  choice: 2\n",
      "  choice: 4\n",
      "  choice: 1\n",
      "  choice: 3\n",
      "A:\n",
      "targets\n",
      "['2']\n",
      "multiple_choice_targets\n",
      "['1', '2', '3', '4']\n",
      "multiple_choice_scores\n",
      "[0, 1, 0, 0]\n",
      "Number of examples: 200\n"
     ]
    }
   ],
   "source": [
    "import jsonlines\n",
    "\n",
    "temp = 0\n",
    "raw_data = []\n",
    "all_data = []\n",
    "with jsonlines.open(dataset) as f:\n",
    "    for line in f.iter():\n",
    "        if temp == 0:\n",
    "            print(line.keys())\n",
    "            for item in line.keys():\n",
    "                print(item)\n",
    "                print(line[item])\n",
    "        temp += 1\n",
    "        raw_data.append(line['inputs'])\n",
    "        all_data.append(line)\n",
    "print(f\"Number of examples: {temp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "066a2037",
   "metadata": {},
   "outputs": [],
   "source": [
    "log = './datasets/logic_grid_puzzle_200.jsonl__method-spp_engine-devgpt4-32k_temp-0.0_topp-1.0_start0-end200__with_sys_mes.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2eee769",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_responses = []\n",
    "\n",
    "with jsonlines.open(log) as f:\n",
    "    for line in f.iter():\n",
    "        try:\n",
    "            raw_responses.append(line['raw_response'][0]['choices'][0]['message']['content'])\n",
    "        except:\n",
    "            raw_responses.append('N/A')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3842c62",
   "metadata": {},
   "source": [
    "# Detecting Digression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59e8e898",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ac160c",
   "metadata": {},
   "source": [
    "[TODO] You need to insert your own api_key of openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc48264e",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36b0cc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_digression(example, response):\n",
    "    \n",
    "    text = f\"Please analyze the following conversation for any digressions and answer 'yes' or 'no'.\\n\"\n",
    "    text += f\"Then, highlight any statements that do not directly contribute to solving the puzzle or are unrelated to the clues provided.\\n\"\n",
    "    text += f\"### Input\\n\\n {example} \\n\\n\"\n",
    "    text += f\"### Conversation\\n\\n {response} \\n\\n\"\n",
    "    text += f\"### Answer: \"\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14262d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_digression_reason(example, response, label):\n",
    "    \n",
    "    text = f\"Please analyze the following conversation for any digressions and answer 'yes' or 'no'.\\n\"\n",
    "    text += f\"Then, highlight any statements that do not directly contribute to solving the puzzle or are unrelated to the clues provided.\\n\"\n",
    "    text += f\"### Input\\n\\n {example} \\n\\n\"\n",
    "    text += f\"### Conversation\\n\\n {response} \\n\\n\"\n",
    "    text += f\"### Answer: {label}.\\nThen, explicitly highlight any statements that do not directly contribute to solving the puzzle or are unrelated to the clues provided. \"\n",
    "    text += f\"Also, providing the rationale why such statements are considered as digression. Or you can change the asnwer, but please also provide the reason for such change and provide the changed answer at the end, e.g., '... Therefore, the answer is xx.'. \"\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b9a88a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_api_gpt4(query):\n",
    "    model = \"gpt-4-1106-preview\"\n",
    "    waiting_time = 0.5\n",
    "    \n",
    "    response = None\n",
    "    while response is None:\n",
    "        try:\n",
    "            messages = [\n",
    "                    {\"role\": \"system\", \"content\": query},\n",
    "            ]\n",
    "            \n",
    "                # ChatGPT API 호출하기\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=model,\n",
    "                messages=messages,\n",
    "                temperature=0.0,\n",
    "                max_tokens=256\n",
    "            )\n",
    "        except:\n",
    "            time.sleep(waiting_time)\n",
    "            if waiting_time < 5:\n",
    "                waiting_time += 0.5\n",
    "            else:\n",
    "                break\n",
    "    if response is not None:\n",
    "        try:\n",
    "            answer = response['choices'][0]['message']['content']\n",
    "        except:\n",
    "            answer = 'N/A'\n",
    "        n_input_tokens = response['usage']['prompt_tokens']\n",
    "        n_output_tokens = response['usage']['completion_tokens']\n",
    "    else:\n",
    "        answer = 'N/A'\n",
    "        n_input_tokens = 0\n",
    "        n_output_tokens = 0\n",
    "        \n",
    "    return answer, n_input_tokens, n_output_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e32ec55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_digression(examples, responses, method='gpt3'):\n",
    "    n_examples = len(examples)\n",
    "    all_input_tokens = 0\n",
    "    all_output_tokens = 0\n",
    "    res = []\n",
    "    \n",
    "    for i in tqdm(range(n_examples)):\n",
    "        if responses[i] != 'N/A':\n",
    "            query = prompt_digression(examples[i], responses[i])\n",
    "            if method == 'gpt3':\n",
    "                ans, n_input_token, n_output_token = call_api(query)\n",
    "            elif method == 'gpt4':\n",
    "                ans, n_input_token, n_output_token = call_api_gpt4(query)\n",
    "            res.append(ans)\n",
    "            all_input_tokens += n_input_token\n",
    "            all_output_tokens += n_output_token\n",
    "        else:\n",
    "            res.append('N/A')\n",
    "        break\n",
    "    print(\"Method: {}\".format(method))\n",
    "    print(\"All input tokens: {}, All output tokens: {}\".format(all_input_tokens, all_output_tokens))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50bfaf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_digression_reason(examples, responses, labels, method='gpt3'):\n",
    "    n_examples = len(examples)\n",
    "    all_input_tokens = 0\n",
    "    all_output_tokens = 0\n",
    "    res = []\n",
    "    \n",
    "    for i in tqdm(range(n_examples)):\n",
    "        if labels[i] != 'N/A':\n",
    "            query = prompt_digression_reason(examples[i], responses[i], labels[i])\n",
    "            if method == 'gpt3':\n",
    "                ans, n_input_token, n_output_token = call_api(query)\n",
    "            elif method == 'gpt4':\n",
    "                ans, n_input_token, n_output_token = call_api_gpt4(query)\n",
    "            res.append(ans)\n",
    "            all_input_tokens += n_input_token\n",
    "            all_output_tokens += n_output_token\n",
    "        else:\n",
    "            res.append('N/A')\n",
    "        break\n",
    "    print(\"Method: {}\".format(method))\n",
    "    print(\"All input tokens: {}, All output tokens: {}\".format(all_input_tokens, all_output_tokens))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6716b8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_label(labels):\n",
    "    res = []\n",
    "    \n",
    "    for item in labels:\n",
    "        if 'yes' in item.lower():\n",
    "            res.append('Yes')\n",
    "        elif 'no' in item.lower():\n",
    "            res.append('No')\n",
    "        elif 'n/a' in item.lower():\n",
    "            res.append('N/A')\n",
    "        else:\n",
    "            raise ValueError(f'{item}')\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ec11a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                               | 0/200 [00:05<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: gpt4\n",
      "All input tokens: 681, All output tokens: 54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "res_gpt4 = detect_digression(raw_data, raw_responses, 'gpt4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84c09a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_gpt4_post = postprocess_label(res_gpt4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "025422fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                               | 0/200 [00:04<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: gpt4\n",
      "All input tokens: 758, All output tokens: 59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "res_gpt4_reason = detect_digression_reason(raw_data, raw_responses, res_gpt4_post, 'gpt4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "558f8c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "no_counts = 0\n",
    "\n",
    "yes_indices, no_indices = [], []\n",
    "\n",
    "for i, item in enumerate(res_gpt4_reason): \n",
    "    if 'not contain any digression' in item.lower():\n",
    "        no_indices.append(i)\n",
    "    elif 'no statements in the conversation that digress' in item.lower():\n",
    "        no_indices.append(i)    \n",
    "    elif 'no digressions' in item.lower():\n",
    "        no_indices.append(i)\n",
    "    elif 'do not directly contribute' in item.lower():\n",
    "        yes_indices.append(i)\n",
    "    elif '### digressions' in item.lower() or 'following statements are digressions' in item.lower():\n",
    "        yes_indices.append(i)    \n",
    "    elif i in [8, 18, 21, 34, 42, 48, 119]:\n",
    "        yes_indices.append(i)\n",
    "    elif i in [38, 40, 46, 110, 126, 167, 194, 196]:\n",
    "        no_indices.append(i)    \n",
    "    else:\n",
    "        print(i)\n",
    "        print(item)\n",
    "        break\n",
    "\n",
    "print(len(yes_indices))\n",
    "print(len(no_indices))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a500130",
   "metadata": {},
   "source": [
    "## Measuring Task Accuracy Change with Digression  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c303d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "labels = []\n",
    "\n",
    "for i, item in enumerate(raw_responses):\n",
    "    try:\n",
    "        preds.append(int(item[-2]))\n",
    "    except:\n",
    "        try:\n",
    "            preds.append(int(item[-1]))\n",
    "        except:\n",
    "            preds.append(0)\n",
    "    labels.append(int(all_data[i]['targets'][0]))\n",
    "\n",
    "preds = np.array(preds)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "477bd43c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 66.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: {}\".format(100 * (preds == labels).sum() / 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "68569b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (yes_digression): 53.03030303030303\n"
     ]
    }
   ],
   "source": [
    "yes_indices = np.array(yes_indices).astype(np.int64)\n",
    "print(\"Accuracy (yes_digression): {}\".format(100 * (preds == labels)[yes_indices].sum() / len(yes_indices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f775ba7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (no_digression): 72.38805970149254\n"
     ]
    }
   ],
   "source": [
    "no_indices = np.array(no_indices).astype(np.int64)\n",
    "print(\"Accuracy (no_digression): {}\".format(100 * (preds == labels)[no_indices].sum() / len(no_indices)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28fc1b7",
   "metadata": {},
   "source": [
    "# Classification of Digression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "82301892",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_classify(response, reason):\n",
    "    \n",
    "    text = f\"Please classify the given reasoning into the one of the following categories: [1] Procedural or Introductory Statements, [2] Repetitive or Confirmatory Statements, [3] Transitional Statements, [4] Irrelevant or Off-Topic Contributions, [5] Misleading or Incorrect Reasoning, [6] Closing or Summarizing Remarks, and [7] Constructive Contributions. You response should be in the form of [], e.g., [1] or [3].\\n\"\n",
    "    text += f\"### Conversation\\n\\n {response} \\n\\n\"\n",
    "    text += f\"### Reasonings\\n\\n {reason} \\n\\n\"\n",
    "    text += f\"### Answer (You response should be in the simple form, e.g., [1] or [3]): \"\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "760624c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_reason(responses, reasons, method='gpt3'):\n",
    "    n_examples = len(responses)\n",
    "    all_input_tokens = 0\n",
    "    all_output_tokens = 0\n",
    "    res = []\n",
    "    \n",
    "    for i in tqdm(range(n_examples)):\n",
    "        if responses[i] != 'N/A':\n",
    "            query = prompt_classify(responses[i], reasons[i])\n",
    "            if method == 'gpt3':\n",
    "                ans, n_input_token, n_output_token = call_api(query)\n",
    "            elif method == 'gpt4':\n",
    "                ans, n_input_token, n_output_token = call_api_gpt4(query)\n",
    "            res.append(ans)\n",
    "            all_input_tokens += n_input_token\n",
    "            all_output_tokens += n_output_token\n",
    "        else:\n",
    "            res.append('N/A')\n",
    "    print(\"Method: {}\".format(method))\n",
    "    print(\"All input tokens: {}, All output tokens: {}\".format(all_input_tokens, all_output_tokens))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3cf0dc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dig_responses = [res_gpt4_reason[idx] for idx in yes_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "749c2cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 66/66 [02:55<00:00,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: gpt4\n",
      "All input tokens: 61844, All output tokens: 383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "classification_gpt4 = classify_reason([raw_responses[idx] for idx in yes_indices], dig_responses, 'gpt4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b88ade3",
   "metadata": {},
   "source": [
    "# Human-like Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c797808d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_human2(example, response):\n",
    "    \n",
    "    text = f\"Please analyze the provided conversation and assess whether it resembles a dialogue between human participants or appears to be an artificial conversation created by multiple AI agents. Please answer 'yes' if it is closed to human conversation or 'no' otherwise.\\n\"\n",
    "    text += f\"Consider factors such as the flow of the conversation, the naturalness of responses, the presence of emotional or personal interjections, and the complexity or variability of language used.\\n\"\n",
    "    #text += f\"Highlight any characteristics that particularly suggest a human or artificial origin of the conversation.\\n\"\n",
    "    #text += f\"### Input\\n\\n {example} \\n\\n\"\n",
    "    text += f\"### Conversation\\n\\n {response} \\n\\n\"\n",
    "    text += f\"### Answer: \"\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0703d2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_human_reason(example, response, label):\n",
    "    \n",
    "    text = f\"Please analyze the provided conversation and assess whether it resembles a dialogue between human participants or appears to be an artificial conversation created by multiple AI agents. Please answer 'yes' if it is closed to human conversation or 'no' otherwise.\\n\"\n",
    "    text += f\"Consider factors such as the flow of the conversation, the naturalness of responses, the presence of emotional or personal interjections, and the complexity or variability of language used.\\n\"\n",
    "    text += f\"### Conversation\\n\\n {response} \\n\\n\"\n",
    "    text += f\"### Answer: {label}\\n\\n\"\n",
    "    text += f\"Then, providing the explicit rationale for the answer by highlight any characteristics that particularly suggest a human or artificial origin of the conversation. Or you can change the asnwer, but please also provide the reason for such change and provide the changed answer at the end, e.g., '... Therefore, the answer is xx.'. \"\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eba786c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_human(examples, responses, method='gpt3'):\n",
    "    n_examples = len(examples)\n",
    "    all_input_tokens = 0\n",
    "    all_output_tokens = 0\n",
    "    res = []\n",
    "    \n",
    "    for i in tqdm(range(n_examples)):\n",
    "        if responses[i] != 'N/A':\n",
    "            query = prompt_human2(examples[i], responses[i])\n",
    "            if method == 'gpt3':\n",
    "                ans, n_input_token, n_output_token = call_api(query)\n",
    "            elif method == 'gpt4':\n",
    "                ans, n_input_token, n_output_token = call_api_gpt4(query)\n",
    "            res.append(ans)\n",
    "            all_input_tokens += n_input_token\n",
    "            all_output_tokens += n_output_token\n",
    "        else:\n",
    "            res.append('N/A')\n",
    "    print(\"Method: {}\".format(method))\n",
    "    print(\"All input tokens: {}, All output tokens: {}\".format(all_input_tokens, all_output_tokens))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "56917230",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_human_reason(examples, responses, labels, method='gpt3'):\n",
    "    n_examples = len(examples)\n",
    "    all_input_tokens = 0\n",
    "    all_output_tokens = 0\n",
    "    res = []\n",
    "    \n",
    "    for i in tqdm(range(n_examples)):\n",
    "        if labels[i] != 'N/A':\n",
    "            query = prompt_human_reason(examples[i], responses[i], labels[i])\n",
    "            if method == 'gpt3':\n",
    "                ans, n_input_token, n_output_token = call_api(query)\n",
    "            elif method == 'gpt4':\n",
    "                ans, n_input_token, n_output_token = call_api_gpt4(query)\n",
    "            res.append(ans)\n",
    "            all_input_tokens += n_input_token\n",
    "            all_output_tokens += n_output_token\n",
    "        else:\n",
    "            res.append('N/A')\n",
    "    print(\"Method: {}\".format(method))\n",
    "    print(\"All input tokens: {}, All output tokens: {}\".format(all_input_tokens, all_output_tokens))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8475de",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_gpt4_human = detect_human(raw_data, raw_responses, 'gpt4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189dac30",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_gpt4_human_post = postprocess_label(res_gpt4_human)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bb015c",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_gpt4_human_reason = detect_human_reason(raw_data, raw_responses, res_gpt4_human_post, 'gpt4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e7c247",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_indices = []\n",
    "ai_indices = []\n",
    "\n",
    "for i, item in enumerate(res_gpt4_human_reason):\n",
    "    if 'yes' in item.lower() and 'human' in item.lower():\n",
    "        human_indices.append(i)\n",
    "    elif 'does resemble a dialogue between human participants' in item.lower() or 'closer to a human conversation' in item.lower():\n",
    "        human_indices.append(i)\n",
    "    elif 'closer to a dialogue between human participants' in item.lower() or i == 162:\n",
    "        human_indices.append(i)\n",
    "    elif 'possibly created by ai agents' in item.lower() or i == 167:\n",
    "        ai_indices.append(i)\n",
    "    elif 'not closely resemble a dialogue between human participants' in item.lower():\n",
    "        ai_indices.append(i)\n",
    "    elif 'created by multiple ai agents' in item.lower():\n",
    "        ai_indices.append(i)\n",
    "    elif 'not resemble a natural dialogue between human participants' in item.lower():\n",
    "        ai_indices.append(i)\n",
    "    elif 'no' in item.split('\\n\\n')[0].lower():\n",
    "        ai_indices.append(i)\n",
    "    else:\n",
    "        print(i)\n",
    "        print(item)\n",
    "        break\n",
    "        \n",
    "print(len(human_indices))\n",
    "print(len(ai_indices))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c816c9",
   "metadata": {},
   "source": [
    "## Comparison of Digression Patterns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "95dcb2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_indices_dig = []\n",
    "ai_indices_dig = []\n",
    "\n",
    "for i, item in enumerate(yes_indices):\n",
    "    if onehot_human[item] == 1:\n",
    "        human_indices_dig.append(i)\n",
    "    else:\n",
    "        ai_indices_dig.append(i)\n",
    "human_indices_dig = np.array(human_indices_dig).astype(np.int64)\n",
    "ai_indices_dig = np.array(ai_indices_dig).astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0e8b40d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.  1.  0. 14.  2.  4.  0.]\n"
     ]
    }
   ],
   "source": [
    "classification_gpt4_post2 = np.array(classification_gpt4_post).astype(np.int64)[human_indices_dig]\n",
    "n_classes = np.zeros(7)\n",
    "\n",
    "for i in range(1, 8):\n",
    "    n_classes[i-1] = (classification_gpt4_post2 == i).sum()\n",
    "print(n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "08629aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6.  1.  0. 27.  5.  1.  0.]\n"
     ]
    }
   ],
   "source": [
    "classification_gpt4_post3 = np.array(classification_gpt4_post).astype(np.int64)[ai_indices_dig]\n",
    "n_classes = np.zeros(7)\n",
    "\n",
    "for i in range(1, 8):\n",
    "    n_classes[i-1] = (classification_gpt4_post3 == i).sum()\n",
    "print(n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c999f54b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82\n",
      "118\n"
     ]
    }
   ],
   "source": [
    "human_indices = []\n",
    "ai_indices = []\n",
    "\n",
    "for i, item in enumerate(res_gpt4_human_all):\n",
    "    if 'yes' in item.lower() and 'human' in item.lower():\n",
    "        human_indices.append(i)\n",
    "    elif 'does resemble a dialogue between human participants' in item.lower() or 'closer to a human conversation' in item.lower():\n",
    "        human_indices.append(i)\n",
    "    elif 'closer to a dialogue between human participants' in item.lower() or i == 162:\n",
    "        human_indices.append(i)\n",
    "    elif 'possibly created by ai agents' in item.lower() or i == 167:\n",
    "        ai_indices.append(i)\n",
    "    elif 'not closely resemble a dialogue between human participants' in item.lower():\n",
    "        ai_indices.append(i)\n",
    "    elif 'created by multiple ai agents' in item.lower():\n",
    "        ai_indices.append(i)\n",
    "    elif 'not resemble a natural dialogue between human participants' in item.lower():\n",
    "        ai_indices.append(i)\n",
    "    elif 'no' in item.split('\\n\\n')[0].lower():\n",
    "        ai_indices.append(i)\n",
    "    else:\n",
    "        print(i)\n",
    "        print(item)\n",
    "        break\n",
    "        \n",
    "print(len(human_indices))\n",
    "print(len(ai_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9206eb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_indices = np.array(human_indices).astype(np.int64)\n",
    "ai_indices = np.array(ai_indices).astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "85cac25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82.0\n"
     ]
    }
   ],
   "source": [
    "onehot_human = np.zeros(200)\n",
    "\n",
    "for item in human_indices:\n",
    "    onehot_human[item] = 1\n",
    "print(onehot_human.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "afee980f",
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_dig = np.zeros(200)\n",
    "\n",
    "for item in yes_indices:\n",
    "    onehot_dig[item] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71df9fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dig_indices = (onehot_dig == 1).nonzero()[0]\n",
    "ai_dig_indices = [dig_indices[idx] for idx in ai_indices_dig]\n",
    "ai_dig_indices_irre = []\n",
    "\n",
    "for i, item in enumerate(ai_dig_indices):\n",
    "    if classification_gpt4_post3[i] == 4:\n",
    "        ai_dig_indices_irre.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2f9a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_ai_irrelevant = np.zeros(200)\n",
    "\n",
    "for item in ai_dig_indices_irre:\n",
    "    onehot_ai_irrelevant[item] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81189528",
   "metadata": {},
   "outputs": [],
   "source": [
    "dig_indices = (onehot_dig == 1).nonzero()[0]\n",
    "human_dig_indices = [dig_indices[idx] for idx in human_indices_dig]\n",
    "human_dig_indices_irre = []\n",
    "\n",
    "for i, item in enumerate(human_dig_indices):\n",
    "    if classification_gpt4_post2[i] == 4:\n",
    "        human_dig_indices_irre.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93755aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_human_irrelevant = np.zeros(200)\n",
    "\n",
    "for item in human_dig_indices_irre:\n",
    "    onehot_human_irrelevant[item] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e869a834",
   "metadata": {},
   "source": [
    "## Measuring Accuracy Change "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4faecfe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (human & digression): 53.84615384615385\n"
     ]
    }
   ],
   "source": [
    "temp = np.array(((onehot_dig == 1) * (onehot_human == 1)).nonzero()[0]).astype(np.int64)\n",
    "print(\"Accuracy (human & digression): {}\".format(100 * (preds == labels)[temp].sum() / len(temp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5685c3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (human & no digression): 67.85714285714286\n"
     ]
    }
   ],
   "source": [
    "temp = np.array(((onehot_dig == 0) * (onehot_human == 1)).nonzero()[0]).astype(np.int64)\n",
    "print(\"Accuracy (human & no digression): {}\".format(100 * (preds == labels)[temp].sum() / len(temp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "77803a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (human & digression): 52.5\n"
     ]
    }
   ],
   "source": [
    "temp = np.array(((onehot_dig == 1) * (onehot_human == 0)).nonzero()[0]).astype(np.int64)\n",
    "print(\"Accuracy (human & digression): {}\".format(100 * (preds == labels)[temp].sum() / len(temp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cf722a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (human & digression): 75.64102564102564\n"
     ]
    }
   ],
   "source": [
    "temp = np.array(((onehot_dig == 0) * (onehot_human == 0)).nonzero()[0]).astype(np.int64)\n",
    "print(\"Accuracy (human & digression): {}\".format(100 * (preds == labels)[temp].sum() / len(temp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "599bafc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (human & digression): 51.851851851851855\n"
     ]
    }
   ],
   "source": [
    "temp = np.array(((onehot_dig == 1) * (onehot_human == 0) * (onehot_ai_irrelevant == 1)).nonzero()[0]).astype(np.int64)\n",
    "print(\"Accuracy (human & digression): {}\".format(100 * (preds == labels)[temp].sum() / len(temp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a4a2aa4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (human & digression): 57.142857142857146\n"
     ]
    }
   ],
   "source": [
    "temp = np.array(((onehot_dig == 1) * (onehot_human == 1) * (onehot_human_irrelevant == 1)).nonzero()[0]).astype(np.int64)\n",
    "print(\"Accuracy (human & digression): {}\".format(100 * (preds == labels)[temp].sum() / len(temp)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d5c166",
   "metadata": {},
   "source": [
    "# Collaborative Effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eae85283",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_collaborative(example, response):\n",
    "    \n",
    "    text = f\"Please analyze the provided conversation to determine the collaborative dynamics among the participants which means that evaluate whether the final conclusion is a result of a combined effort, with each participant contributing significantly, or if it is predominantly led by a single participant. Please answer 'yes' if there is combined effort or 'no' otherwise.\\n\"\n",
    "    #text += f\"Then, highlight any statements that do not directly contribute to solving the puzzle or are unrelated to the clues provided.\\n\"\n",
    "    text += f\"### Input\\n\\n {example} \\n\\n\"\n",
    "    text += f\"### Conversation\\n\\n {response} \\n\\n\"\n",
    "    text += f\"### Answer: \"\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4e2c7928",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_collaborative_reason(example, response, label):\n",
    "    \n",
    "    text = f\"Please analyze the provided conversation to determine the collaborative dynamics among the participants which means that evaluate whether the final conclusion is a result of a combined effort, with each participant contributing significantly, or if it is predominantly led by a single participant. Please answer 'yes' if there is combined effort or 'no' otherwise.\\n\"\n",
    "    text += f\"### Input\\n\\n {example} \\n\\n\"\n",
    "    text += f\"### Conversation\\n\\n {response} \\n\\n\"\n",
    "    text += f\"### Answer: {label}\\n\\n\"\n",
    "    text += f\"Then, providing the explicit rationale for the answer. Or you can change the asnwer, but please also provide the reason for such change and provide the changed answer at the end, e.g., '... Therefore, the answer is xx.'. \"\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "786ff979",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_collaborative(examples, responses, method='gpt3'):\n",
    "    n_examples = len(examples)\n",
    "    all_input_tokens = 0\n",
    "    all_output_tokens = 0\n",
    "    res = []\n",
    "    \n",
    "    for i in tqdm(range(n_examples)):\n",
    "        if responses[i] != 'N/A':\n",
    "            query = prompt_collaborative(examples[i], responses[i])\n",
    "            if method == 'gpt3':\n",
    "                ans, n_input_token, n_output_token = call_api(query)\n",
    "            elif method == 'gpt4':\n",
    "                ans, n_input_token, n_output_token = call_api_gpt4(query)\n",
    "            res.append(ans)\n",
    "            all_input_tokens += n_input_token\n",
    "            all_output_tokens += n_output_token\n",
    "        else:\n",
    "            res.append('N/A')\n",
    "    print(\"Method: {}\".format(method))\n",
    "    print(\"All input tokens: {}, All output tokens: {}\".format(all_input_tokens, all_output_tokens))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "477198c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_collaborative_reason(examples, responses, labels, method='gpt3'):\n",
    "    n_examples = len(examples)\n",
    "    all_input_tokens = 0\n",
    "    all_output_tokens = 0\n",
    "    res = []\n",
    "    \n",
    "    for i in tqdm(range(n_examples)):\n",
    "        if labels[i] != 'N/A':\n",
    "            query = prompt_collaborative_reason(examples[i], responses[i], labels[i])\n",
    "            if method == 'gpt3':\n",
    "                ans, n_input_token, n_output_token = call_api(query)\n",
    "            elif method == 'gpt4':\n",
    "                ans, n_input_token, n_output_token = call_api_gpt4(query)\n",
    "            res.append(ans)\n",
    "            all_input_tokens += n_input_token\n",
    "            all_output_tokens += n_output_token\n",
    "        else:\n",
    "            res.append('N/A')\n",
    "    print(\"Method: {}\".format(method))\n",
    "    print(\"All input tokens: {}, All output tokens: {}\".format(all_input_tokens, all_output_tokens))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "482f420a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                               | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: gpt4\n",
      "All input tokens: 702, All output tokens: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "res_gpt4_collabo = detect_collaborative(raw_data, raw_responses, 'gpt4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "31c8ab3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_gpt4_collabo_post = postprocess_label(res_gpt4_collabo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6d1e13a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                               | 0/200 [00:08<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: gpt4\n",
      "All input tokens: 752, All output tokens: 196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "res_gpt4_collabo_reason = detect_collaborative_reason(raw_data, raw_responses, res_gpt4_collabo_post, 'gpt4')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "human",
   "language": "python",
   "name": "human"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
